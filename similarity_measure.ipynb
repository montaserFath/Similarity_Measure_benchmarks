{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils as utils\n",
    "import sklearn.linear_model as models\n",
    "from sklearn.model_selection import cross_validate\n",
    "from similartiy_fun import numerical_similarity_fun, categorical_similarity_fun, voting_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity1(o1, o2):\n",
    "    return np.dot(o1,o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, sep = ',', names = None):\n",
    "    df = pd.read_table(path , header=None, sep=sep, names = names)\n",
    "    data = df.values\n",
    "    return data\n",
    "\n",
    "names = ['age', 'W eduction', 'H eduction', 'no of children', 'religon', 'working', 'H of occupation', 'standard of living', 'media expouser', 'cmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_data(data,  numerical_columns):\n",
    "    processed_data = []\n",
    "    \n",
    "    processed_data_n = data[:,numerical_columns]\n",
    "    processed_data_n = np.concatenate((processed_data_n, data[:,-1].reshape(-1,1)), axis = 1)\n",
    "    \n",
    "    categorical_cols = np.setdiff1d(range(len(data[1])-1),numerical_columns)\n",
    "    processed_data_c = data[:,categorical_cols]\n",
    "    processed_data_c = np.concatenate((processed_data_c, data[:,-1].reshape(-1,1)), axis = 1)\n",
    "                    \n",
    "    return processed_data_n, processed_data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_Matrix(data, similarity_function):\n",
    "    #sm = np.empty((len(data),len(data)),dtype=float)\n",
    "    sm = []\n",
    "    lables = []\n",
    "    #lables = np.empty((len(data),len(data)))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i,len(data)): # only get the upper right of the similarity matrix\n",
    "\n",
    "            sm.append(similarity_function(data[i][:-1],data[j][:-1])) #exculde the label\n",
    "            lables.append(data[i][-1] == data[j][-1])\n",
    "           \n",
    "    return np.array(sm).reshape(-1,1),np.array(lables).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(classifer_data):\n",
    "    classifier_data = classifer_data[classifer_data[:,1].argsort()] #sort by lables\n",
    "    lable0_count = (classifier_data[:,1] == 0).sum()\n",
    "    lable1_count = len(classifier_data)- lable0_count\n",
    "    slice_size = min(lable0_count, lable1_count)    \n",
    "    # shuffle each lable part individually\n",
    "    classifier_data[:lable0_count] = utils.shuffle(classifier_data[:lable0_count]) \n",
    "    classifier_data[lable0_count:] = utils.shuffle(classifier_data[lable0_count:])\n",
    "   # sample from each lable by the slice size\n",
    "    classifier_data0 = classifier_data[:slice_size]\n",
    "    classifier_data1 = classifier_data[-slice_size:]\n",
    "    # concatente the samples\n",
    "    classifier_data = np.concatenate((classifier_data0, classifier_data1), axis= 0)\n",
    "    return classifier_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_metrics(path_to_data, data_sep, numerical_columns, similarity_fn = None, similarity_type=1): #similarity types 1 - numerical 2 - categorical 3 - mixed\n",
    "    # numerical columns = indecies of numerical cols\n",
    "    data = get_data(path_to_data, data_sep)\n",
    "    processed_data_n, processed_data_c = processed_data(data, numerical_columns)\n",
    "    \n",
    "    \n",
    "    if (similarity_type == 1):\n",
    "        data = processed_data_n\n",
    "    elif (similarity_type == 2):\n",
    "        data = processed_data_c\n",
    "#     else:\n",
    "#         data = np.concatenate((processed_data_n[:][:-1], processed_data_c), axis = 1)\n",
    "        \n",
    "    \n",
    "    if (similarity_type == 3):\n",
    "        voting_similarity_n = lambda o1,o2 :voting_similarity(o1,o2,True)\n",
    "        measures_n, lables_n = get_similarity_Matrix(processed_data_n,voting_similarity_n)\n",
    "        measures_c, lables_c = get_similarity_Matrix(processed_data_c,voting_similarity)\n",
    "        measures = np.average((measures_n, measures_c), axis=1)\n",
    "        lables = lables_c\n",
    "    else:\n",
    "        measures , lables = get_similarity_Matrix(data, similarity_fn)\n",
    "        \n",
    "        \n",
    "    classifier_data = sample_data(np.concatenate((measures,lables),axis=1))\n",
    "    classifer_input = classifier_data[:,0].reshape(-1,1)\n",
    "    classifer_targets = classifier_data[:,1]\n",
    "    \n",
    "    \n",
    "    clf = models.LogisticRegression(max_iter=400)\n",
    "    #train the classifier\n",
    "    scoring = ['f1_macro', 'precision_macro', 'recall_macro']\n",
    "    scores = cross_validate(clf, classifer_input, classifer_targets, cv=5, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    for score in scores:\n",
    "        if(score == 'fit_time' or score == 'score_time'):\n",
    "            continue\n",
    "        print(score, ': ', np.average(scores[score]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data links, sep and neumaric cols indices\n",
    "maram_data = ('https://archive.ics.uci.edu/ml/machine-learning-databases/cmc/cmc.data', ',', [0,3]) \n",
    "safana_data = ('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', ',', [0,1]) \n",
    "nosiba_data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data', ',', [1,3,5,7,9]\n",
    "ola_data = ('https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data', ' ', [1, 4, 7, 10, 12, 15, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Numerical Similarity ###############\n",
      "############### Categorical Similarity ###############\n",
      "############### Mix Similarity ###############\n",
      "------------ Mixed fun ----------------------\n"
     ]
    }
   ],
   "source": [
    "print('############### Numerical Similarity ###############')\n",
    "# for similarity_fun in numerical_similarity_fun:\n",
    "#     print('------------',similarity_fun,'----------------------')\n",
    "#     get_similarity_metrics(*nosiba_data, numerical_similarity_fun[similarity_fun], similarity_type=1)\n",
    "\n",
    "print('############### Categorical Similarity ###############')\n",
    "# for similarity_fun in categorical_similarity_fun:\n",
    "#     print('------------',similarity_fun,'----------------------')\n",
    "#     get_similarity_metrics(*nosiba_data, categorical_similarity_fun[similarity_fun], similarity_type=2)\n",
    "    \n",
    "print('############### Mix Similarity ###############')\n",
    "print('------------','Mixed fun','----------------------')\n",
    "get_similarity_metrics(*maram_data, similarity_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(path_to_data, data_sep, numerical_columns, numerical_similarity_fun, categorical_similarity_fun):\n",
    "    \n",
    "    print('############### Numerical Similarity ###############')\n",
    "    for similarity_fun in numerical_similarity_fun:\n",
    "        print('------------',similarity_fun,'----------------------')\n",
    "        get_similarity_metrics(*maram_data, numerical_similarity_fun[similarity_fun], [0,3], similarity_type=1)\n",
    "\n",
    "    print('############### Categorical Similarity ###############')\n",
    "    for similarity_fun in categorical_similarity_fun:\n",
    "        print('------------',similarity_fun,'----------------------')\n",
    "        get_similarity_metrics(*maram_data, categorical_similarity_fun[similarity_fun], [0,3], similarity_type=2)\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_args = {\n",
    "    'Maram': maram_data\n",
    "    ,'Safana': safana_data\n",
    "    ,'Nosiba': nosiba_data\n",
    "    ,'Ola': ola_data\n",
    "}\n",
    "for name, data_args in all_data_args.items():\n",
    "    print('************************', name ,'***************************')\n",
    "    print_metrics(*data_args, numerical_similarity_fun, categorical_similarity_fun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
