{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils as utils\n",
    "import sklearn.linear_model as models\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity1(o1, o2):\n",
    "    return np.dot(o1,o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, names = None):\n",
    "    df = pd.read_table(path , header=None, sep=\",\", names = names)\n",
    "    data = df.values\n",
    "    return data\n",
    "\n",
    "names = ['age', 'W eduction', 'H eduction', 'no of children', 'religon', 'working', 'H of occupation', 'standard of living', 'media expouser', 'cmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_Matrix(data, similarity_function):\n",
    "    #sm = np.empty((len(data),len(data)),dtype=float)\n",
    "    sm = []\n",
    "    lables = []\n",
    "    #lables = np.empty((len(data),len(data)))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i,len(data)): # only get the upper right of the similarity matrix\n",
    "            sm.append(similarity_function(data[i][:-1],data[j][:-1])) #exculde the label\n",
    "            lables.append(data[i][-1] == data[j][-1])\n",
    "           \n",
    "    return np.array(sm).reshape(-1,1),np.array(lables).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(classifer_data):\n",
    "    classifier_data = classifer_data[classifer_data[:,1].argsort()] #sort by lables\n",
    "    lable0_count = (classifier_data[:,1] == 0).sum()\n",
    "    lable1_count = len(classifier_data)- lable0_count\n",
    "    slice_size = min(lable0_count, lable1_count)    \n",
    "    # shuffle each lable part individually\n",
    "    classifier_data[:lable0_count] = utils.shuffle(classifier_data[:lable0_count]) \n",
    "    classifier_data[lable0_count:] = utils.shuffle(classifier_data[lable0_count:])\n",
    "   # sample from each lable by the slice size\n",
    "    classifier_data0 = classifier_data[:slice_size]\n",
    "    classifier_data1 = classifier_data[-slice_size:]\n",
    "    # concatente the samples\n",
    "    classifier_data = np.concatenate((classifier_data0, classifier_data1), axis= 0)\n",
    "    return classifier_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_metrics(data, similarity_fn,  numerical_columns, similarity_type=1): #similarity types 1 - numerical 2 - categorical 3 - mixed\n",
    "    # numerical columns = no of  numerical cols\n",
    "    \n",
    "    get_similarity_Matrix(data, similarity1)\n",
    "    classifier_data = sample_data(np.concatenate((measures,lables),axis=1))\n",
    "    classifer_input = classifier_data[:,0].reshape(-1,1)\n",
    "    classifer_targets = classifier_data[:,1]\n",
    "    \n",
    "    \n",
    "    clf = models.LogisticRegression(max_iter=400)\n",
    "    #train the classifier\n",
    "    scoring = ['f1_macro', 'precision_macro', 'recall_macro']\n",
    "    scores = cross_validate(clf, classifer_input, classifer_targets, cv=5, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    for score in scores:\n",
    "        if(score == 'fit_time' or score == 'score_time'):\n",
    "            continue\n",
    "        print(score, ': ', np.average(scores[score]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1_macro :  0.5051951658311531\n",
      "test_precision_macro :  0.5073063947300558\n",
      "test_recall_macro :  0.5071886991202504\n"
     ]
    }
   ],
   "source": [
    "get_similarity_metrics(data, similarity1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
